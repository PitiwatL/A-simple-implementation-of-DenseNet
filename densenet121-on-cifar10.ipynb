{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nimport seaborn as sns\nimport numpy as np\nimport pandas as pd\nimport itertools","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-01-16T20:51:57.338248Z","iopub.execute_input":"2023-01-16T20:51:57.339217Z","iopub.status.idle":"2023-01-16T20:52:04.342375Z","shell.execute_reply.started":"2023-01-16T20:51:57.339088Z","shell.execute_reply":"2023-01-16T20:52:04.341102Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# Preparing Images\ncifar10 = tf.keras.datasets.cifar10\n(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n\ny_train = y_train.flatten()\ny_test = y_test.flatten()\n\nclasses = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']","metadata":{"execution":{"iopub.status.busy":"2023-01-16T20:52:04.344886Z","iopub.execute_input":"2023-01-16T20:52:04.345535Z","iopub.status.idle":"2023-01-16T20:52:10.351393Z","shell.execute_reply.started":"2023-01-16T20:52:04.345495Z","shell.execute_reply":"2023-01-16T20:52:10.350091Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n170500096/170498071 [==============================] - 2s 0us/step\n170508288/170498071 [==============================] - 2s 0us/step\n","output_type":"stream"}]},{"cell_type":"code","source":"input_shape = (32, 32, 3)\n\nx_train=x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], 3)\nx_train=x_train / 255.0\nx_test = x_test.reshape(x_test.shape[0], x_test.shape[1], x_test.shape[2], 3)\nx_test=x_test / 255.0\n\ny_train = tf.one_hot(y_train.astype(np.int32), depth=10)\ny_test = tf.one_hot(y_test.astype(np.int32), depth=10)","metadata":{"execution":{"iopub.status.busy":"2023-01-16T20:52:10.352756Z","iopub.execute_input":"2023-01-16T20:52:10.353698Z","iopub.status.idle":"2023-01-16T20:52:11.051782Z","shell.execute_reply.started":"2023-01-16T20:52:10.353661Z","shell.execute_reply":"2023-01-16T20:52:11.050477Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"2023-01-16 20:52:11.022908: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Setting Hyperparameters\nbatch_size = 32\nnum_classes = 10\nepochs = 5","metadata":{"execution":{"iopub.status.busy":"2023-01-16T20:52:13.661512Z","iopub.execute_input":"2023-01-16T20:52:13.661939Z","iopub.status.idle":"2023-01-16T20:52:13.667201Z","shell.execute_reply.started":"2023-01-16T20:52:13.661905Z","shell.execute_reply":"2023-01-16T20:52:13.666100Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Original DenseNet121 with the witout ImageNet weights\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Model\n\nDenseNet121 = tf.keras.applications.DenseNet121(include_top=False, weights=None, \n                                                input_shape=(32,32,3))\nDenseNet121.trainable = False\n\ninput_layer = layers.Input(shape=(32, 32, 3)) \n#x = layers.Conv2D(3, 1, strides=1, use_bias=False)(input_layer)\nx = DenseNet121(input_layer)\nx = layers.GlobalAveragePooling2D()(x)\nx = layers.Dense(10, activation = 'softmax')(x)\n    \nDenseNet121_ = Model(input_layer, outputs = x)\nDenseNet121_.compile(loss = 'categorical_crossentropy', \n                 optimizer = tf.keras.optimizers.SGD(learning_rate=0.003), \n                 metrics = [\"accuracy\"])","metadata":{"execution":{"iopub.status.busy":"2023-01-16T22:08:19.571161Z","iopub.execute_input":"2023-01-16T22:08:19.571643Z","iopub.status.idle":"2023-01-16T22:08:23.128531Z","shell.execute_reply.started":"2023-01-16T22:08:19.571604Z","shell.execute_reply":"2023-01-16T22:08:23.127293Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"history = DenseNet121_.fit(x_train, y_train, batch_size=batch_size, epochs= 20)\ntest_loss, test_acc = DenseNet121_.evaluate(x_test, y_test)","metadata":{"execution":{"iopub.status.busy":"2023-01-16T22:08:25.920804Z","iopub.execute_input":"2023-01-16T22:08:25.921238Z","iopub.status.idle":"2023-01-16T22:51:28.714812Z","shell.execute_reply.started":"2023-01-16T22:08:25.921200Z","shell.execute_reply":"2023-01-16T22:51:28.713676Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Epoch 1/20\n1563/1563 [==============================] - 135s 81ms/step - loss: 2.3023 - accuracy: 0.0897\nEpoch 2/20\n1563/1563 [==============================] - 129s 82ms/step - loss: 2.3018 - accuracy: 0.0950\nEpoch 3/20\n1563/1563 [==============================] - 127s 82ms/step - loss: 2.3014 - accuracy: 0.0995\nEpoch 4/20\n1563/1563 [==============================] - 130s 83ms/step - loss: 2.3011 - accuracy: 0.1099\nEpoch 5/20\n1563/1563 [==============================] - 128s 82ms/step - loss: 2.3007 - accuracy: 0.1117\nEpoch 6/20\n1563/1563 [==============================] - 127s 82ms/step - loss: 2.3003 - accuracy: 0.1193\nEpoch 7/20\n1563/1563 [==============================] - 129s 83ms/step - loss: 2.3000 - accuracy: 0.1273\nEpoch 8/20\n1563/1563 [==============================] - 127s 81ms/step - loss: 2.2996 - accuracy: 0.1286\nEpoch 9/20\n1563/1563 [==============================] - 129s 82ms/step - loss: 2.2992 - accuracy: 0.1351\nEpoch 10/20\n1563/1563 [==============================] - 128s 82ms/step - loss: 2.2989 - accuracy: 0.1420\nEpoch 11/20\n1563/1563 [==============================] - 125s 80ms/step - loss: 2.2985 - accuracy: 0.1401\nEpoch 12/20\n1563/1563 [==============================] - 125s 80ms/step - loss: 2.2981 - accuracy: 0.1457\nEpoch 13/20\n1563/1563 [==============================] - 125s 80ms/step - loss: 2.2978 - accuracy: 0.1472\nEpoch 14/20\n1563/1563 [==============================] - 127s 81ms/step - loss: 2.2974 - accuracy: 0.1532\nEpoch 15/20\n1563/1563 [==============================] - 126s 80ms/step - loss: 2.2971 - accuracy: 0.1419\nEpoch 16/20\n1563/1563 [==============================] - 128s 82ms/step - loss: 2.2967 - accuracy: 0.1493\nEpoch 17/20\n1563/1563 [==============================] - 129s 83ms/step - loss: 2.2964 - accuracy: 0.1520\nEpoch 18/20\n1563/1563 [==============================] - 126s 81ms/step - loss: 2.2960 - accuracy: 0.1509\nEpoch 19/20\n1563/1563 [==============================] - 126s 81ms/step - loss: 2.2957 - accuracy: 0.1549\nEpoch 20/20\n1563/1563 [==============================] - 126s 81ms/step - loss: 2.2953 - accuracy: 0.1608\n313/313 [==============================] - 29s 82ms/step - loss: 2.2948 - accuracy: 0.1617\n","output_type":"stream"}]},{"cell_type":"code","source":"# Original DenseNet121 with the fixed ImageNet weights\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Model\n\nDenseNet121 = tf.keras.applications.DenseNet121(include_top=False, \n                                              weights = 'imagenet', input_shape=(32,32,3))\nDenseNet121.trainable = False\n\ninput_layer = layers.Input(shape=(32, 32, 3)) \n#x = layers.Conv2D(3, 1, strides=1, use_bias=False)(input_layer)\nx = DenseNet121(input_layer)\nx = layers.GlobalAveragePooling2D()(x)\nx = layers.Dense(10, activation = 'softmax')(x)\n    \nDenseNet121_ = Model(input_layer, outputs = x)\nDenseNet121_.compile(loss = 'categorical_crossentropy', \n                 optimizer = tf.keras.optimizers.SGD(learning_rate=0.003), \n                 metrics = [\"accuracy\"])","metadata":{"execution":{"iopub.status.busy":"2023-01-16T20:52:14.889828Z","iopub.execute_input":"2023-01-16T20:52:14.890828Z","iopub.status.idle":"2023-01-16T20:52:19.516493Z","shell.execute_reply.started":"2023-01-16T20:52:14.890774Z","shell.execute_reply":"2023-01-16T20:52:19.515108Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n29089792/29084464 [==============================] - 0s 0us/step\n29097984/29084464 [==============================] - 0s 0us/step\n","output_type":"stream"}]},{"cell_type":"code","source":"history = DenseNet121_.fit(x_train, y_train, batch_size=batch_size, epochs=epochs)\ntest_loss, test_acc = DenseNet121_.evaluate(x_test, y_test)","metadata":{"execution":{"iopub.status.busy":"2023-01-16T20:52:23.720079Z","iopub.execute_input":"2023-01-16T20:52:23.720488Z","iopub.status.idle":"2023-01-16T21:03:23.647605Z","shell.execute_reply.started":"2023-01-16T20:52:23.720451Z","shell.execute_reply":"2023-01-16T21:03:23.646603Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"2023-01-16 20:52:25.249834: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/5\n1563/1563 [==============================] - 133s 80ms/step - loss: 1.5494 - accuracy: 0.4598\nEpoch 2/5\n1563/1563 [==============================] - 122s 78ms/step - loss: 1.2533 - accuracy: 0.5668\nEpoch 3/5\n1563/1563 [==============================] - 125s 80ms/step - loss: 1.1824 - accuracy: 0.5913\nEpoch 4/5\n1563/1563 [==============================] - 122s 78ms/step - loss: 1.1421 - accuracy: 0.6085\nEpoch 5/5\n1563/1563 [==============================] - 123s 79ms/step - loss: 1.1166 - accuracy: 0.6144\n313/313 [==============================] - 29s 82ms/step - loss: 1.1311 - accuracy: 0.6115\n","output_type":"stream"}]},{"cell_type":"code","source":"# Original DenseNet121 with the adjustable ImageNet weights\n\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Model\n\nDenseNet121 = tf.keras.applications.DenseNet121(include_top=False, \n                                              weights = 'imagenet', input_shape=(32,32,3))\nDenseNet121.trainable = True\n\ninput_layer = layers.Input(shape=(32, 32, 3)) \n#x = layers.Conv2D(3, 1, strides=1, use_bias=False)(input_layer)\nx = DenseNet121(input_layer)\nx = layers.GlobalAveragePooling2D()(x)\nx = layers.Dense(10, activation = 'softmax')(x)\n    \nDenseNet121_ = Model(input_layer, outputs = x)\nDenseNet121_.compile(loss = 'categorical_crossentropy', \n                 optimizer = tf.keras.optimizers.SGD(learning_rate=0.003), \n                 metrics = [\"accuracy\"])","metadata":{"execution":{"iopub.status.busy":"2023-01-16T21:03:23.649814Z","iopub.execute_input":"2023-01-16T21:03:23.650516Z","iopub.status.idle":"2023-01-16T21:03:27.993122Z","shell.execute_reply.started":"2023-01-16T21:03:23.650476Z","shell.execute_reply":"2023-01-16T21:03:27.991754Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"history = DenseNet121_.fit(x_train, y_train, batch_size=batch_size, epochs=epochs)\ntest_loss, test_acc = DenseNet121_.evaluate(x_test, y_test)","metadata":{"execution":{"iopub.status.busy":"2023-01-16T21:03:27.994517Z","iopub.execute_input":"2023-01-16T21:03:27.995084Z","iopub.status.idle":"2023-01-16T21:44:07.764386Z","shell.execute_reply.started":"2023-01-16T21:03:27.995048Z","shell.execute_reply":"2023-01-16T21:44:07.763375Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Epoch 1/5\n1563/1563 [==============================] - 492s 308ms/step - loss: 1.0841 - accuracy: 0.6283\nEpoch 2/5\n1563/1563 [==============================] - 478s 306ms/step - loss: 0.6700 - accuracy: 0.7695\nEpoch 3/5\n1563/1563 [==============================] - 481s 308ms/step - loss: 0.5321 - accuracy: 0.8166\nEpoch 4/5\n1563/1563 [==============================] - 479s 306ms/step - loss: 0.4321 - accuracy: 0.8506\nEpoch 5/5\n1563/1563 [==============================] - 478s 306ms/step - loss: 0.3561 - accuracy: 0.8768\n313/313 [==============================] - 30s 85ms/step - loss: 0.5355 - accuracy: 0.8206\n","output_type":"stream"}]}]}